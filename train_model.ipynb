{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dataset_location = './Food ingredient recognition.v4i.tfrecord'\n",
    "dataset_location = \"/mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/Food ingredient recognition.v4i.tfrecord\" # Punya Andi\n",
    "tfrecord_name = \"food-ingredient.tfrecord\"\n",
    "print(os.path.exists(dataset_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.TFRecordDataset(dataset_location + f\"/train/{tfrecord_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'image/object/bbox/ymin' : tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmin' : tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax' : tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax' : tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text' : tf.io.VarLenFeature(tf.string),\n",
    "    'image/object/class/label' : tf.io.VarLenFeature(tf.int64),\n",
    "    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def _parse_function(example_proto):\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    for key in ['image/object/bbox/ymin', 'image/object/bbox/xmin', 'image/object/bbox/ymax', 'image/object/bbox/xmax', 'image/object/class/text', 'image/object/class/label']:\n",
    "        parsed_example[key] = tf.sparse.to_dense(parsed_example[key])\n",
    "    return parsed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "\n",
    "class_ids = [\n",
    "    \"-\",\n",
    "    \"almond\",\n",
    "    \"apple\",\n",
    "    \"avocado\",\n",
    "    \"beef\",\n",
    "    \"bell pepper\",\n",
    "    \"blueberry\",\n",
    "    \"bread\",\n",
    "    \"broccoli\",\n",
    "    \"butter\",\n",
    "    \"carrot\",\n",
    "    \"cheese\",\n",
    "    \"chilli\",\n",
    "    \"cookie\",\n",
    "    \"corn\",\n",
    "    \"cucumber\",\n",
    "    \"egg\",\n",
    "    \"eggplant\",\n",
    "    \"garlic\",\n",
    "    \"lemon\",\n",
    "    \"milk\",\n",
    "    \"mozarella cheese\",\n",
    "    \"mushroom\",\n",
    "    \"mussel\",\n",
    "    \"onion\",\n",
    "    \"oyster\",\n",
    "    \"parmesan cheese\",\n",
    "    \"pasta\",\n",
    "    \"pork rib\",\n",
    "    \"potato\",\n",
    "    \"salmon\",\n",
    "    \"scallop\",\n",
    "    \"shrimp\",\n",
    "    \"strawberry\",\n",
    "    \"toast bread\",\n",
    "    \"tomato\",\n",
    "    \"tuna\",\n",
    "    \"yogurt\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "def preprocess_dataset(parsed_dataset):\n",
    "    image = tf.image.decode_jpeg(parsed_dataset['image/encoded'])\n",
    "    label = parsed_dataset['image/object/class/label']\n",
    "    bounding_box = tf.stack([\n",
    "        parsed_dataset['image/object/bbox/xmin'],\n",
    "        parsed_dataset['image/object/bbox/ymin'],\n",
    "        parsed_dataset['image/object/bbox/xmax'],\n",
    "        parsed_dataset['image/object/bbox/ymax']\n",
    "    ], axis=-1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return {\n",
    "        'images': image,\n",
    "        'bounding_boxes' : {\n",
    "            'boxes': tf.cast(bounding_box, tf.float32),\n",
    "            'classes': tf.cast(label, tf.int32)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def visualize_data(image, bounding_boxes):\n",
    "    image = np.array(image)\n",
    "    inference_resizing = keras_cv.layers.Resizing(\n",
    "    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",
    "    )\n",
    "    image = inference_resizing([image])\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        image,\n",
    "        value_range=(0, 255),\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        scale=5,\n",
    "        bounding_box_format='xywh',\n",
    "        y_pred=bounding_boxes\n",
    "    )\n",
    "\n",
    "augmenter = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': <tf.Tensor 'args_2:0' shape=(4, 640, 640, None) dtype=float32>, 'bounding_boxes': {'boxes': tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None, 4), dtype=float32), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(5,), dtype=int64)), 'classes': tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:1\", shape=(None,), dtype=float32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(5,), dtype=int64))}}\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(4, 640, 640, None), dtype=tf.float32, name=None), {'boxes': TensorSpec(shape=(4, 32, 4), dtype=tf.float32, name=None), 'classes': TensorSpec(shape=(4, 32), dtype=tf.float32, name=None)})>\n"
     ]
    }
   ],
   "source": [
    "from keras_cv import bounding_box\n",
    "\n",
    "train_data = dataset_train.map(_parse_function).map(preprocess_dataset).shuffle(buffer_size=10_000).ragged_batch(4, drop_remainder=True)\n",
    "train_data = train_data.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    print(inputs)\n",
    "    # return tf.RaggedTensor.to_tensor(inputs[\"images\"]), bounding_box.to_dense(inputs[\"bounding_boxes\"], max_boxes=32)\n",
    "    return inputs[\"images\"], bounding_box.to_dense(inputs[\"bounding_boxes\"], max_boxes=32)\n",
    "\n",
    "train_data = train_data.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "\n",
    "# pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "#     \"yolo_v8_m_pascalvoc\", bounding_box_format=\"xywh\"\n",
    "# )\n",
    "# image = keras.utils.load_img(\"stock-photo-airport-with-many-airplanes-at-beautiful-sunset-324754607.jpg\")\n",
    "# image = np.array(image)\n",
    "# # print(image.shape)\n",
    "\n",
    "# visualization.plot_image_gallery(\n",
    "#     np.array([image]),\n",
    "#     value_range=(0, 255),\n",
    "#     rows=1,\n",
    "#     cols=1,\n",
    "#     scale=5,)\n",
    "# inference_resizing = keras_cv.layers.Resizing(\n",
    "#     640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",
    "# )\n",
    "# image_batch = inference_resizing([image])\n",
    "# # print(image_batch)\n",
    "# class_ids = [\n",
    "#     \"Aeroplane\",\n",
    "#     \"Bicycle\",\n",
    "#     \"Bird\",\n",
    "#     \"Boat\",\n",
    "#     \"Bottle\",\n",
    "#     \"Bus\",\n",
    "#     \"Car\",\n",
    "#     \"Cat\",\n",
    "#     \"Chair\",\n",
    "#     \"Cow\",\n",
    "#     \"Dining Table\",\n",
    "#     \"Dog\",\n",
    "#     \"Horse\",\n",
    "#     \"Motorbike\",\n",
    "#     \"Person\",\n",
    "#     \"Potted Plant\",\n",
    "#     \"Sheep\",\n",
    "#     \"Sofa\",\n",
    "#     \"Train\",\n",
    "#     \"Tvmonitor\",\n",
    "#     \"Total\",\n",
    "# ]\n",
    "# # class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "# # y_pred = pretrained_model.predict(image_batch)\n",
    "\n",
    "# # print(y_pred)\n",
    "\n",
    "# for sample in train_data_unbatched.take(1):\n",
    "#     image = np.array(sample['images'])\n",
    "#     inference_resizing = keras_cv.layers.Resizing(\n",
    "#     640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xyxy\"\n",
    "#     )\n",
    "#     image = inference_resizing([image])\n",
    "#     y_pred = pretrained_model.predict(image)\n",
    "#     print(y_pred)\n",
    "#     visualization.plot_bounding_box_gallery(\n",
    "#         image,\n",
    "#         value_range=(0, 255),\n",
    "#         rows=1,\n",
    "#         cols=1,\n",
    "#         y_pred=y_pred,\n",
    "#         scale=5,\n",
    "#         font_scale=0.7,\n",
    "#         bounding_box_format=\"xyxy\",\n",
    "#         class_mapping=class_mapping,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of classes in the dataset\n",
    "# unique_classes = set()\n",
    "# for parsed_dataset in train_data:\n",
    "#     classes = parsed_dataset['bounding_boxes']['classes'].numpy()\n",
    "#     unique_classes.update(np.unique(classes))\n",
    "\n",
    "# NUM_CLASSES = len(unique_classes)\n",
    "NUM_CLASSES = len(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained backbone\n",
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone_coco\",\n",
    "    include_rescaling = True,\n",
    ")\n",
    "\n",
    "model = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze = 133\n",
    "# Freeze to up to 133 layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i < freeze:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown \u001b[1m34s\u001b[0m 34s/step - loss: 11649.3496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717567372.182729   68483 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 42ms/step - loss: 11649.1953\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:03:22.726262: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-05 13:03:22.726838: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - loss: 11649.1035\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:03:56.645465: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-05 13:03:56.646597: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-06-05 13:03:56.646621: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 4928007475644499037\n",
      "2024-06-05 13:03:56.646628: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 758603102464478797\n",
      "2024-06-05 13:03:56.646668: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6071733332022983152\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
