{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 20:35:23.769126: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 20:35:24.390722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/model.pb\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/model.pb\"\n",
    "if (not os.path.exists(path)):\n",
    "    path = \"./model.pb\"\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 20:35:39.175924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.202084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.202136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.204436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.204489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.204520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.341494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.341561: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.341569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-05 20:35:39.341604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-05 20:35:39.341625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1717594638.386956  187200 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1717594638.387018  187200 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-06-05 20:37:18.394185: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/model.pb\n",
      "2024-06-05 20:37:18.419274: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-06-05 20:37:18.419302: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/model.pb\n",
      "2024-06-05 20:37:18.576164: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-06-05 20:37:18.592871: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-06-05 20:37:19.697796: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /mnt/c/Tugas Raihan/Kuliah/Matkul/Semester 6/Bangkit/Machine-Learning-Capstone/model.pb\n",
      "2024-06-05 20:37:19.878990: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 1484808 microseconds.\n",
      "2024-06-05 20:37:20.040488: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p3p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "error: failed while converting: 'main': \n",
      "Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \n",
      "TF Select ops: Conv2D\n",
      "Details:\n",
      "\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x384x128xf32>) -> (tensor<?x?x?x128xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x768x256xf32>) -> (tensor<?x?x?x256xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p3p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p3p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: Conv2D\nDetails:\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x384x128xf32>) -> (tensor<?x?x?x128xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x768x256xf32>) -> (tensor<?x?x?x256xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187200/1112580409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       )\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     return self._optimize_tflite_model(\n\u001b[1;32m   1369\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_io\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_new_quantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m   \u001b[0mmodel_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m   \u001b[0mconversion_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conversion_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m   1013\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    365\u001b[0m               \u001b[0menable_mlir_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           )\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   return _run_deprecated_conversion_binary(\n",
      "\u001b[0;31mConverterError\u001b[0m: Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p3p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"yolov8_detector_1/pa_fpn_p3p4p5_pre_conv_1/convolution@__inference___call___30356\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___31639\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: Conv2D\nDetails:\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x384x128xf32>) -> (tensor<?x?x?x128xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n\ttf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x768x256xf32>) -> (tensor<?x?x?x256xf32>) : {data_format = \"NHWC\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
